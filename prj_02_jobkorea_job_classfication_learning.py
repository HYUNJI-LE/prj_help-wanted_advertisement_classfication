# -*- coding: utf-8 -*-
"""Project_01_job_classfication_learning_2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12qniKC7vlP2rYKEzi41k9TTdFcd_CzZq
"""


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.text import *
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
import re
from keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

df = pd.read_csv('./datasets/help_wanted_advertisement_nosale.csv')
df.drop('Unnamed: 0', axis=1, inplace=True)
print(df)

df_dup = df['title'].duplicated() 
print(df_dup)

sum_dup = df.title.duplicated().sum()
print(sum_dup)

df = df.drop_duplicates(subset=['title'])

sum_dup = df.title.duplicated().sum()
print(sum_dup)

print(df.info())

print(df.iloc[40000:51300])

df.reset_index(drop=True, inplace=True)

X = df['title']
Y = df['category']
print(X.head())
print(Y.head())

encoder = LabelEncoder()        
encoder.fit(Y)
Y = encoder.transform(Y)
print(Y)

Y = to_categorical(Y) 
print(Y)

from konlpy.tag import Okt

okt = Okt()

for i in range(len(X)):
   X[i] = okt.morphs(X[i]) 
print(X)

print(X[0])

stopwords = pd.read_csv('./datasets/stopwords.csv', index_col=0)
print(stopwords.head())
print(stopwords.iloc[11])

for j in range(len(X)):
   result = []
   for i in range(len(X[j])):
      if X[j][i] not in list(stopwords['stopword']):
         result.append(X[j][i]) 
   X[j] = result
print(X)

for j in range(len(X)):
   result = '' 
   for i in range(len(X[j])):
      result += ' '+X[j][i]
   X[j] = result
print(X)

token = Tokenizer()
token.fit_on_texts(X)     
Xtoken = token.texts_to_sequences(X)
print(Xtoken[:10])

for i in Xtoken[:5]:
  print(i)
for i in X[:5]:
  print(i)

max = 0
for i in range(len(Xtoken)):
  if max < len(Xtoken[i]):
     max = len(Xtoken[i])
print(max)

Xpad = pad_sequences(Xtoken, max)  
print(Xpad)

X_train,X_test,Y_train,Y_test = train_test_split(Xpad, Y, test_size=0.2)
print(X_train.shape)

wordsize = len(token.word_index)+1                   
print(wordsize)


#모델
model = Sequential()
model.add(Embedding(wordsize,300,input_length=max))
model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(128,activation='tanh', return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(64,activation='tanh', return_sequences=True))
model.add(Dropout(0.3)) #과적합방지
model.add(LSTM(32,activation='tanh', return_sequences=True))
model.add(Flatten())
model.add(Dense(7, activation='softmax'))



print(model.summary())

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

fit_hist = model.fit(X_train,Y_train,batch_size=100,epochs=5,validation_data=(X_test,Y_test))

#테스트 데이터로 검증하기
score = model.evaluate(X_test,Y_test, batch_size=100, verbose=0)




print('loss:', score[0])

print('accuracy:', score[1])





plt.plot(fit_hist.history['loss'])   
plt.plot(fit_hist.history['val_loss']) 
plt.show()





#다른 데이터로 한번 더 검증해보기

test_ad = pd.read_csv('./datasets/help_wanted_advertisement_test_nosale.csv',index_col=0)
test_ad.head()

test_ad.rename(columns={'0':'title'}, inplace=True)
print(test_ad.head(875))

category=encoder.classes_         
print(category)

test_ad['predicted']=0
test_ad.head()

for i in range(len(test_ad)): 
   test_title = test_ad['title'][i]
   test_title = okt.morphs(test_title)
   result = []
   for j in range(len(test_title)): 
     if test_title[j] not in list(stopwords['stopword']):
       result.append(test_title[j])
   test_title = result
   result = '' 
   for k in range(len(test_title)):
     result += ' '+ test_title[k] 
   test_title = result
   test_title = token.texts_to_sequences([test_title]) 
   test_title = pad_sequences(test_title, max)
   predict = model.predict(test_title)
   print(predict)
   test_ad['predicted'][i] = category[np.argmax(predict)]

test_ad.head(20)

test_ad['OX'] = 0
for i in range(len(test_ad)):
  if test_ad['category'][i] == test_ad['predicted'][i]:
    test_ad['OX'][i] = 'O'
  else:
    test_ad['OX'][i] = 'X'
test_ad.head(30)

test_ad.OX.value_counts()

#test_ad.to_csv('./datasets/result3')

print('accuracy is :', test_ad.OX.value_counts(normalize=True)[0]*100)